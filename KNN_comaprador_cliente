import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import NearestNeighbors

# Definindo um limite de similaridade (quanto mais próximo de 1, mais similar)
SIMILARITY_THRESHOLD = 0.5

# Vetorização usando TF-IDF para converter os nomes dos comércios em vetores
vectorizer_name = TfidfVectorizer(analyzer='char', ngram_range=(2, 3))
tfidf_matrix_name_1 = vectorizer_name.fit_transform(df0['NOME_FANTASIA'])
tfidf_matrix_name_2 = vectorizer_name.transform(df_google['DSC_ESTABELECIMENTO'])

# Vetorização usando TF-IDF para converter os locais em vetores
vectorizer_local = TfidfVectorizer(analyzer='char', ngram_range=(2, 3))
tfidf_matrix_local_1 = vectorizer_local.fit_transform(df0['LOCAL'])
tfidf_matrix_local_2 = vectorizer_local.transform(df_google['LOCAL'])

# Modelo KNN para encontrar as similaridades baseadas nos nomes
knn_name = NearestNeighbors(n_neighbors=1, metric='cosine')
knn_name.fit(tfidf_matrix_name_2)

# Modelo KNN para encontrar as similaridades baseadas nos locais
knn_local = NearestNeighbors(n_neighbors=1, metric='cosine')
knn_local.fit(tfidf_matrix_local_2)

# Lista para armazenar os resultados
matches = []

# Procurar a correspondência mais próxima para cada nome de comércio e local no df0
for idx, (comercio_1, local_1) in enumerate(zip(df0['NOME_FANTASIA'], df0['LOCAL'])):
    # Obter o vetor correspondente ao nome do comércio atual
    vector_comercio_1 = tfidf_matrix_name_1[idx]
    vector_local_1 = tfidf_matrix_local_1[idx]

    # Encontrar a similaridade com os nomes e locais em df_google
    distances_name, indices_name = knn_name.kneighbors(vector_comercio_1)
    distances_local, indices_local = knn_local.kneighbors(vector_local_1)

    # Calcular a média das similaridades de nome e local
    avg_similarity = (1 - distances_name[0][0] + 1 - distances_local[0][0]) / 2

    # Checar se a similaridade média é maior que o limiar definido
    if avg_similarity >= SIMILARITY_THRESHOLD:
        # Armazenar o índice do df0, índice correspondente no df_google e a similaridade média
        matches.append((idx, indices_name[0][0], avg_similarity))

# Criar um novo DataFrame resultante do merge baseado nas correspondências
merged_df = pd.DataFrame()

for idx1, idx2, similarity in matches:
    # Combina as duas linhas de df0 e df_google que têm alta similaridade
    combined_row = {
        'NOME_FANTASIA': df0.iloc[idx1]['NOME_FANTASIA'],
        'LOCAL': df0.iloc[idx1]['LOCAL'],
        'DSC_ESTABELECIMENTO': df_google.iloc[idx2]['DSC_ESTABELECIMENTO'],
        'ENDERECO': df_google.iloc[idx2]['LOCAL'],
        'LATITUDE': df_google.iloc[idx2]['LATITUDE'],
        'LONGITUDE': df_google.iloc[idx2]['LONGITUDE'],
        'Similaridade': similarity
    }
    
    # Adiciona a linha combinada ao DataFrame
    merged_df = pd.concat([merged_df, pd.DataFrame([combined_row])], ignore_index=True)

# Visualização do DataFrame final
merged_df
